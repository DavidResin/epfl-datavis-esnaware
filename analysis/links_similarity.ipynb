{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.read_pickle(\"../data/df_subset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    try:\n",
    "        s1 = set(list1)\n",
    "        s2 = set(list2)\n",
    "    except:\n",
    "        print(list1)\n",
    "        print(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links = df_subset[['Title', 'Links']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_sim = np.empty((len(df_links), len(df_links)))\n",
    "for i, row1 in enumerate(df_links.itertuples()):\n",
    "    for j, row2 in enumerate(df_links.itertuples()):\n",
    "        jaccard_sim[i, j] = jaccard_similarity(row1.Links, row2.Links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "conf = pyspark.SparkConf().setMaster(\"local[*]\").setAll([\n",
    "                                   ('spark.executor.memory', '12g'),  # find\n",
    "                                   ('spark.driver.memory','4g'), # your\n",
    "                                   ('spark.driver.maxResultSize', '2G') # setup\n",
    "                                  ])\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# FIX for Spark 2.x\n",
    "locale = sc._jvm.java.util.Locale\n",
    "locale.setDefault(locale.forLanguageTag(\"en-US\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(df_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|               Title|               Links|              Title2|              Links2|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Climate change de...|[2010 Russian wil...|Climate change de...|[2010 Russian wil...|\n",
      "|Climate change de...|[2010 Russian wil...|Khabibullo Abduss...|[Astrophysics, Bi...|\n",
      "|Climate change de...|[2010 Russian wil...|   Accuracy in Media|[2012 Benghazi at...|\n",
      "|Climate change de...|[2010 Russian wil...|     Robert Aderholt|[105th United Sta...|\n",
      "|Climate change de...|[2010 Russian wil...|          Jerry Agar|[CFRB, Chicago, D...|\n",
      "|Climate change de...|[2010 Russian wil...|Alexis de Tocquev...|[501(c)(3), ACT! ...|\n",
      "|Climate change de...|[2010 Russian wil...|Alternative for G...|[2013 Bavaria sta...|\n",
      "|Climate change de...|[2010 Russian wil...|American Farm Bur...|[AFL–CIO, Agribus...|\n",
      "|Climate change de...|[2010 Russian wil...|American Petroleu...|[1967 Oil Embargo...|\n",
      "|Climate change de...|[2010 Russian wil...| An Appeal to Reason|[AR4, Amazon Stan...|\n",
      "|Climate change de...|[2010 Russian wil...|      Ernesto Araújo|[Abraham Weintrau...|\n",
      "|Climate change de...|[2010 Russian wil...|Association of Am...|[1993 Clinton hea...|\n",
      "|Climate change de...|[2010 Russian wil...|Australian Coal A...|[Australian coal,...|\n",
      "|Climate change de...|[2010 Russian wil...|Australian Enviro...|[Australian Labor...|\n",
      "|Climate change de...|[2010 Russian wil...|            Tim Ball|[American Indian ...|\n",
      "|Climate change de...|[2010 Russian wil...|        Steve Bannon|[2016 United Stat...|\n",
      "|Climate change de...|[2010 Russian wil...|Andy Barr (Americ...|[113th United Sta...|\n",
      "|Climate change de...|[2010 Russian wil...|       John Barrasso|[116th United Sta...|\n",
      "|Climate change de...|[2010 Russian wil...|          Joe Barton|[115th United Sta...|\n",
      "|Climate change de...|[2010 Russian wil...|        Joe Bastardi|[AccuWeather, Acc...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df_links_crosses = spark_df.crossJoin(spark_df\\\n",
    "                                            .withColumnRenamed('Title', 'Title2')\n",
    "                                            .withColumnRenamed('Links', 'Links2'))\\\n",
    "                                 .persist()\n",
    "spark_df_links_crosses.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = spark_df_links_crosses.rdd.map(lambda x: jaccard_similarity(x.Links, x.Links2)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard = np.array(jaccard).reshape(len(df_links), len(df_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(937, 937)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yasser/anaconda3/envs/dataviz/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_links['Jaccard'] = jaccard.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_links.to_csv(\"../data/df_jaccard_sim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dataviz] *",
   "language": "python",
   "name": "conda-env-dataviz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
